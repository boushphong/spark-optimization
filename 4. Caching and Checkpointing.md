# Caching and Checkpointing

## Caching 
### Why Caching?

![image](https://user-images.githubusercontent.com/59940078/182026295-c83c3d6b-7e30-4a25-9760-b665324f423d.png)

### Caching Mechanics

![image](https://user-images.githubusercontent.com/59940078/182026335-6020ef1d-f796-4eca-b712-79d2334e9cca.png)

### Caching Options

![image](https://user-images.githubusercontent.com/59940078/182027156-6ddc4774-c6c0-476a-8361-f3236e64e971.png)

### Caching Trade-Offs

![image](https://user-images.githubusercontent.com/59940078/182027423-8d7e5ba7-0f4d-4ec8-914d-01d3f80e3049.png)

## Recommendations
1) Only cache what's being reused a lot
- Don't cache too much or you risk the executors running out of memory (OOM Error)
- The **LRU(least-recently-used)** data will be evicted

2) If data fits in memory, use MEMORY_ONLY (default)
- Most CPU efficient

3) If data is larger use MEMORY_ONLY_SER
- More CPU intensive, but still faster than anything else

4) Use disk caching only for really expensive computations
- Simple filters take just as much (or even less) to recompute than reread from disk

## Checkpointing

- Saves the RDD/DF to external storage and forgets it lineage.
- Makes an intermediate RDD/DF available to other jobs.
- Takes more space and is slower than caching.
- Does not use Spark memory.
- Does not force recomputation of a partition if a node fails.

# Checkpointing vs Caching

![image](https://user-images.githubusercontent.com/59940078/182145219-aa9ce4cd-3ff1-43dd-82fd-603c954baa0e.png)

![image](https://user-images.githubusercontent.com/59940078/182145574-570a6e1c-09aa-43fd-af52-5520c62b1761.png)
